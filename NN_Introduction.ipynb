{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg7sKb32HKu+OVR+vvlULM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaralAminpour/IVM_supplementary_materials/blob/main/NN_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuron Structure\n",
        "\n",
        "Neural Networks started off trying to mimic how the brain's neurons work, but they've since shifted towards more of an engineering approach to improve how we do machine learning. Even so, it's useful to have a quick look at the biological inspiration behind it all before we dive deeper.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/Picture1.png\" width = \"400\" >\n",
        "\n",
        "- **Dendrites**: These are extensions of the neuron that act as the input channels. They receive chemical signals from other neurons and convert them into electrical signals.\n",
        "- **Soma**: Also known as the cell body, this part of the neuron integrates the electrical signals received from dendrites to determine if the neuron will activate and send a signal along to other neurons.\n",
        "- **Axon**: This is a long, slender projection that transmits the electrical signal (action potential) away from the neuron's soma toward other neurons.\n",
        "- **Myelin Sheath**: Some axons are wrapped in this protective sheath, which helps speed up the transmission of the action potential over long distances.\n",
        "- **Synapses**: These are the junctions where neurons communicate with each other, transferring information from one neuron to the next.\n",
        "- **Chemical Synapses**: In this type, there's a small gap between neurons where the signal is transferred using chemical messengers called neurotransmitters, which are released from one neuron and bind to receptors on the next.\n",
        "- **Neurotransmitters**: These chemicals can either excite the next neuron, prompting it to send a signal, or inhibit it from sending a signal.\n",
        "- **Excitatory and Inhibitory Synapses**: These are the two types of chemical synapses. Excitatory synapses encourage the next neuron to send a signal, while inhibitory synapses discourage it from doing so.\n",
        "\n",
        "Each component of the neuron plays a critical role in processing and transmitting information throughout the nervous system.\n"
      ],
      "metadata": {
        "id": "PUi6t-aECGfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Artificial neurons vs Biological neurons\n",
        "\n",
        "The concept of artificial neural networks comes from biological neurons found in animal brains So they share a lot of similarities in structure and function wise.\n",
        "\n",
        "**Structure:** The structure of artificial neural networks is inspired by biological neurons. A biological neuron has a cell body or soma **to process the impulses**, dendrites **to receive them**, and an axon that **transfers them to other neurons**.  The input nodes of artificial neural networks receive input signals, the hidden layer nodes compute these input signals, and the output layer nodes compute the final output by processing the hidden layer’s results using **activation functions**.\n",
        "\n",
        "**Synapses:** Synapses are the links between biological neurons that enable the **transmission of impulses from dendrites to the cell body**. Synapses are the **weights that join the one-layer nodes to the next-layer nodes** in artificial neurons. The strength of the links is determined by the weight value.\n",
        "\n",
        "**Learning:** In biological neurons, learning happens in the cell body nucleus or soma, which has a nucleus that helps to **process the impulses**. An action potential is produced and travels through the axons if the impulses are powerful enough to reach the threshold. This becomes possible by synaptic plasticity, which represents the ability of synapses to become stronger or weaker over time in reaction to changes in their activity.\n",
        "\n",
        "In artificial neural networks, **backpropagation** is a technique used for learning, which **adjusts the weights between nodes according to the error or differences between predicted and actual outcomes.**\n",
        "\n",
        "**Activation:** In biological neurons, activation is the firing rate of the neuron which happens when the **impulses are strong enough to reach the threshold**. In artificial neural networks, A mathematical function known as an activation function maps the input to the output, and executes activations."
      ],
      "metadata": {
        "id": "sndu5TgPtV0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Biological motivation and connections\n",
        "\n",
        "The basic computational unit of the brain is a neuron. Approximately 86 billion neurons can be found in the human nervous system and they are connected with approximately 10^14 - 10^15 synapses. The diagram below shows a cartoon drawing of a biological neuron (left) and a common mathematical model (right). Each neuron receives input signals from its dendrites and produces output signals along its (single) axon. The axon eventually branches out and connects via synapses to dendrites of other neurons.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/Picture2.png\" width = \"700\" >\n",
        "\n",
        "\n",
        "In a computational model, a neuron is represented as a node that processes incoming signals and produces an output. Here's how it works: signals travel through pathways analogous to axons in the biological sense, where each signal is assigned a variable (like \\( x_0 \\)). This signal is then altered by a corresponding weight (such as \\( w_0 \\)) before it reaches the next neuron. The weight \\( w_0x_0 \\) represents the strength and type of connection—whether it amplifies the signal (excitatory with a positive weight) or diminishes it (inhibitory with a negative weight). This mimics the way biological synapses control the influence of one neuron on another.\n",
        "\n",
        "The weights—these crucial elements of the neural network—are adjustable. They are 'learned' through repeated exposure to data during the training process. As the network processes more data, it adjusts the weights to improve its predictions, much like how our brains strengthen or weaken synaptic connections based on experiences.\n",
        "\n",
        "Once the signals reach a neuron, they are collected by structures akin to dendrites and brought together in the neuron's main body, just like the summing junction in biological neurons. Here, all the incoming weighted signals are totaled. If this total surpasses a specific threshold—a predefined limit that determines whether the neuron should activate—the neuron outputs a signal. This output then travels down what would be considered the neuron's axon in a biological context.\n",
        "\n",
        "One simplification in this computational model is that we don't consider the exact timing of each signal. Instead, we focus on how often the neuron fires, or its firing rate. This rate is assumed to carry the essential information, rather than the precise pattern of spikes. This approach is based on the 'rate code' theory of neural communication, which postulates that it's the number of spikes over time, not the exact timing of them, that's most important for conveying information."
      ],
      "metadata": {
        "id": "Kr1_pUTy3Drp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Coarse model**: It's crucial to acknowledge that the way we model neurons in artificial neural networks is quite simplified compared to their biological counterparts. Real neurons come in various types, each with unique characteristics and functions. In a living brain, dendrites are responsible for intricate nonlinear calculations, far beyond the simple signal processing we typically model in artificial networks. Also, synapses in nature are not merely single values representing strength; they're dynamic and complex, involving a multitude of factors that affect their behavior.\n",
        "\n",
        "Furthermore, in certain biological systems, the precise timing of a neuron's firing—down to the exact millisecond—is critical, which challenges the assumption that the frequency of firing is all that matters (the rate code model). Given these complexities, and many others we simplify or overlook, it's common for neuroscientists to express a bit of frustration when direct comparisons are made between the functioning of neural networks in AI and the workings of the human brain."
      ],
      "metadata": {
        "id": "VvVeBMhcim7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An artificial neural network (ANN)\n",
        "\n",
        "is a computational model that is inspired by the way biological neural networks in the human brain process information. It is a key tool used in machine learning and artificial intelligence, designed to simulate the way humans learn and recognize patterns.\n",
        "\n",
        "Here’s a breakdown of its key components and how it functions:\n",
        "\n",
        "- **Structure**: An ANN is composed of a large number of interconnected processing elements called neurons, which are organized in layers. There are typically three types of layers: an input layer, one or more hidden layers, and an output layer.\n",
        "\n",
        "- **Neurons**: Each neuron in a network acts as a computational unit that receives inputs (either from raw data or from the outputs of other neurons), processes these inputs, and generates an output. This is typically done by summing the weighted inputs, adding a bias, and then passing the result through a nonlinear activation function.\n",
        "\n",
        "- **Weights and Biases**: The 'synapses' of an ANN are represented by weights that adjust as learning proceeds. The strength and sign of these weights determine the influence one neuron has on another. Biases are additional parameters that shift the activation function to better fit the data.\n",
        "\n",
        "- **Learning**: ANNs learn through a process called training, where the network is fed data, makes predictions, and then adjusts its weights and biases based on the error of its predictions. This is often done using algorithms such as gradient descent and backpropagation.\n",
        "\n",
        "- **Activation Functions**: These functions determine whether a neuron should be activated or not, based on the weighted sum of the inputs. Common activation functions include the sigmoid, tanh, and ReLU (Rectified Linear Unit) functions.\n",
        "\n",
        "- **Applications**: ANNs are used for a wide range of applications such as image and speech recognition, natural language processing, medical diagnosis, stock market prediction, and many forms of classification and regression analysis.\n",
        "\n",
        "ANNs are powerful because they can approximate any continuous function given a sufficient number of neurons and layers, which is known as the universal approximation theorem. This flexibility allows ANNs to tackle complex problems that are difficult to solve using traditional programming techniques."
      ],
      "metadata": {
        "id": "IfO26Ajwd8PI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How biases come to picture\n",
        "\n",
        "Introducing a bias term into an Artificial Neural Network (ANN) is a crucial step in the network's ability to accurately model complex patterns. The role of the bias is similar to the intercept in a linear regression equation—it allows the model to better fit the data by providing an additional degree of freedom.\n",
        "\n",
        "Here's a more detailed explanation:\n",
        "\n",
        "In the learning process of an ANN, we aim to adjust the weights of the connections between neurons so that for a given set of inputs, the network produces the desired output. The weights control how much influence one neuron has over another. Initially, these weights are often set to small random values, and the network doesn't perform well.\n",
        "\n",
        "As the network learns, it incrementally adjusts the weights based on the difference between the predicted output and the actual output—a process that's repeated many times over the entire dataset. However, if we only adjusted the weights, the model could only represent linear relationships that pass through the origin of the coordinate system (where the input value is zero).\n",
        "\n",
        "This limitation is where the bias comes in. By adding a bias term to the equation, we effectively shift the activation function to the left or right, which allows the network to represent linear relationships that do not pass through the origin. The bias term gives the neuron the flexibility to activate (or not) even when all input signals are zero.\n",
        "\n",
        "The equation for the output of a single neuron with a bias term looks like this:\n",
        "\n",
        "$$\n",
        "\\text{output} = \\text{activation function}\\left(\\sum (\\text{weights} \\times \\text{inputs}) + \\text{bias}\\right)\n",
        "$$\n",
        "\n",
        "With the bias term, the network can better capture the patterns in the data, regardless of whether those patterns are centered around the origin or not. This is especially important because in real-world data, it's highly unlikely that all the relationships we want to model will conveniently intersect the origin point.\n",
        "\n",
        "In summary, the bias term is essential for providing the model with the full range of motion needed to find the best possible fit to the data, beyond what adjusting weights alone could achieve. It's a small but powerful tweak that significantly enhances the neural network's capability to model complex functions."
      ],
      "metadata": {
        "id": "ahcTzeFgyVrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling one neuron\n"
      ],
      "metadata": {
        "id": "FZQHJYnV354c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single neuron as a linear classifier\n",
        "\n",
        "The operational principle of a single neuron in a neural network is mathematically analogous to **linear classifiers** you may have encountered before. A neuron can exhibit a preference for certain input patterns, showing a high level of activation (close to 1) for favored patterns or a low level of activation (close to 0) for others. By coupling this neuron with a suitable **loss function**, we can mold it into a linear classifier.\n",
        "\n",
        "**Binary Softmax classifier**: Take the Binary Softmax classifier as an instance. Here, the output of the neuron after applying the sigmoid function, denoted as $ \\sigma(\\sum_{i} w_i x_i + b) $, can be interpreted as the probability that a given class label $ y_i $ is 1, given the input features $ x_i $ and the learned parameters $ w $ (the weights) and $ b $ (the bias). The probability of the alternative class (where $ y_i $ is 0) is simply $ 1 - P(y_i=1 | x_i; w) $, ensuring that the total probability sums up to 1. The **cross-entropy loss function**, familiar from linear classification contexts, can then be applied to optimize this neuron, yielding a binary Softmax classifier, also recognized as **logistic regression**. The predictions hinge on whether the neuron's output is above or below the threshold of 0.5, given that the sigmoid function's output is confined within the range from 0 to 1.\n",
        "\n",
        "**Binary SVM classifier**: Alternatively, if we choose to attach a **max-margin hinge loss** to the neuron's output, we steer the training process towards a binary Support Vector Machine (SVM) classifier. This type of classifier aims for the largest margin between the data points of different classes, which can be advantageous for generalization.\n",
        "\n",
        "**Regularization interpretation**: From another angle, if we consider regularization, common to both SVM and Softmax classification, it can be likened to a process of **gradual forgetting within a biological framework**. Regularization penalizes large weights, effectively nudging them towards zero with each update during training, akin to how a biological system might gradually diminish the synaptic strengths that are not frequently used.\n",
        "\n",
        "In essence, even a solitary neuron within a neural network has the potential to act as a binary classifier—whether it's a Softmax or an SVM—by drawing on these mathematical principles and interpretations."
      ],
      "metadata": {
        "id": "jjfdmZNYjMvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation Function: Sigmoid Function\n",
        "\n",
        "In the realm of artificial neural networks, each neuron—or rather, each node—calculates the dot product of its inputs and the corresponding weights. This process is akin to taking several pairs of numbers, multiplying each pair together, and then summing up all the products. This sum is then adjusted by adding a bias, a unique value for each neuron that helps to fine-tune the output.\n",
        "\n",
        "Following this, the neuron applies an activation function, which in many introductory cases is the sigmoid function. The sigmoid function, expressed mathematically as $ \\sigma(x) = \\frac{1}{1 + e^{-x}} $, has a distinctive 'S' shaped curve. **It smoothly maps the input values, which can be any real number, to a range between 0 and 1.** This is useful because it **converts the dot product—a potentially large or small value—into something manageable** that tells the network how 'activated' or 'fired up' the neuron should be.\n",
        "\n",
        "The choice of the sigmoid function isn't arbitrary. It's historically popular because it closely resembles the way biological neurons seem to work: they either fire or they don't, with a gradual buildup as inputs increase. However, it's not the only activation function used in neural networks. Towards the end of this section, we'll explore other activation functions that can be employed, each with its own mathematical characteristics and use cases, tailored to different aspects of learning and pattern recognition that the network aims to achieve."
      ],
      "metadata": {
        "id": "7jkvNbughP4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How do Artificial Neural Networks learn?\n",
        "\n",
        "Artificial Neural Networks (ANNs) learn through a process called training, during which they adjust their internal parameters to make better predictions or decisions based on input data. Here's a step-by-step breakdown of how this learning process typically works:\n",
        "\n",
        "1. **Initialization**: Before learning begins, the weights (the parameters that determine the importance of input signals) and biases (parameters that allow the model to fit better with training data) in the network are usually initialized with small random values.\n",
        "\n",
        "2. **Feedforward**: During the feedforward phase, input data is passed through the network. Each neuron in the network processes the input by performing a weighted sum of the inputs, adds a bias, and then applies an activation function to the result. The activation function's output determines the neuron's output signal, which then becomes the input for the next layer in the network.\n",
        "\n",
        "3. **Loss Calculation**: The output of the network is compared to the desired output, and the difference between them is calculated using a loss function. The loss function measures the error of the network's predictions and provides a single value that the network aims to minimize through training.\n",
        "\n",
        "4. **Backpropagation**: Backpropagation is used to calculate the gradient of the loss function with respect to each weight and bias in the network. This process involves applying the chain rule from calculus to compute the gradients systematically from the output layer back through to the input layer.\n",
        "\n",
        "5. **Weight Update**: Once the gradients are computed, the weights and biases are updated, typically using an optimization algorithm like gradient descent. This involves nudging the weights and biases in the opposite direction of the gradient by a small amount, proportional to a learning rate parameter. The learning rate controls how big a step is taken during each update and is crucial for the convergence and performance of the network.\n",
        "\n",
        "6. **Iterate**: Steps 2-5 are repeated for many iterations over the training dataset, with the network continuing to adjust its weights and biases to reduce the loss.\n",
        "\n",
        "7. **Evaluation**: After the training is complete, the network's performance is evaluated on a separate dataset not seen during training, called the validation set, to ensure that the network generalizes well to new data.\n",
        "\n",
        "8. **Fine-tuning**: Based on the network's performance on the validation set, further fine-tuning of the model may occur, which can involve adjusting the learning rate, trying different architectures, or using regularization techniques to prevent overfitting.\n",
        "\n",
        "Through these iterative processes, ANNs learn the complex relationships within the data they are trained on, allowing them to make predictions or decisions when presented with new, unseen data.\n"
      ],
      "metadata": {
        "id": "6qKD0LGOs0ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview of a Neural Network’s Learning Process\n",
        "\n",
        "The learning (training) process of a neural network is an iterative process in which the calculations are carried out forward and backward through each layer in the network until the loss function is minimized.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/learning_image1.webp\" width = \"700\" >\n",
        "\n",
        "The entire learning process can be divided into three main parts:\n",
        "\n",
        "\n",
        "*   Forward propagation (Forward pass)\n",
        "*   Calculation of the loss function\n",
        "*   Backward propagation (Backward pass/Backpropagation)\n",
        "\n",
        "We’ll begin with forward propagation.\n"
      ],
      "metadata": {
        "id": "-ZUDvFF14sPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward propagation (Feed Forward Networks)\n",
        "\n",
        "A feedforward network consists of an input layer, one or more hidden layers, and an output layer. The input layer receives the input into the neural network, and each input has a weight attached to it.\n",
        "\n",
        "The weights associated with each input are numerical values. These weights are an indicator of the importance of the input in predicting the final output. For example, an input associated with a large weight will have a greater influence on the output than an input associated with a small weight.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/learning2.png\" width = \"700\" >\n",
        "\n",
        "\n",
        "When a neural network is first trained, it is first fed with input. Since the neural network isn’t trained yet, we don’t know which weights to use for each input. And so, each input is randomly assigned a weight. Since the weights are randomly assigned, the neural network will likely make the wrong predictions. It will give out the incorrect output.\n",
        "\n",
        "When the neural network gives out the incorrect output, this leads to an output error. This error is the difference between the actual and predicted outputs. A cost function measures this error.\n",
        "\n",
        "The cost function (J) indicates how accurately the model performs. It tells us how far-off our predicted output values are from our actual values. It is also known as the error. Because the cost function quantifies the error, we aim to minimize the cost function.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/minimum_loss.png\" width = \"400\" >\n",
        "\n",
        "\n",
        "What we want is to reduce the output error. Since the weights affect the error, we will need to readjust the weights. We have to adjust the weights such that we have a combination of weights that minimizes the cost function.\n"
      ],
      "metadata": {
        "id": "CrdXN-Y7AIEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This is where Backpropagation comes in…\n",
        "\n",
        "Backpropagation allows us to readjust our weights to reduce output error. The error is propagated backward during backpropagation from the output to the input layer. This error is then used to calculate the gradient of the cost function with respect to each weight.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/back_propogation.png\" width = \"700\" >\n",
        "\n",
        "Essentially, backpropagation aims to calculate the negative gradient of the cost function. This negative gradient is what helps in adjusting of the weights. It gives us an idea of how we need to change the weights so that we can reduce the cost function.\n",
        "\n",
        "Backpropagation uses the chain rule to calculate the gradient of the cost function. The chain rule involves taking the derivative. This involves calculating the partial derivative of each parameter. These derivatives are calculated by differentiating one weight and treating the other(s) as a constant. As a result of doing this, we will have a gradient.\n",
        "\n",
        "Since we have calculated the gradients, we will be able to adjust the weights."
      ],
      "metadata": {
        "id": "q6ZCxPgHDYQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent\n",
        "\n",
        "The weights are adjusted using a process called gradient descent.\n",
        "\n",
        "Gradient descent is an optimization algorithm that is used to find the weights that minimize the cost function. Minimizing the cost function means getting to the minimum point of the cost function. So, gradient descent aims to find a weight corresponding to the cost function’s minimum point.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/cost_min.png\" width = \"400\" >\n",
        "\n",
        "\n",
        "To find this weight, we must navigate down the cost function until we find its minimum point.\n",
        "\n",
        "But first, to navigate the cost function, we need two things: the direction in which to navigate and the size of the steps for navigating."
      ],
      "metadata": {
        "id": "9a0E1_kKEErL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Direction\n",
        "\n",
        "The direction for navigating the cost function is found using the gradient.\n",
        "\n",
        "### The Gradient\n",
        "\n",
        "To know in which direction to navigate, gradient descent uses backpropagation. More specifically, it uses the gradients calculated through backpropagation. These gradients are used for determining the direction to navigate to find the minimum point.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/gradient.png\" width = \"500\" >\n",
        "\n",
        "Specifically, we aim to find the negative gradient. This is because a negative gradient indicates a decreasing slope. A decreasing slope means that moving downward will lead us to the minimum point. For example:"
      ],
      "metadata": {
        "id": "yt1_U7dyEUOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Step Size\n",
        "\n",
        "The step size for navigating the cost function is determined using the learning rate.\n",
        "\n",
        "###Learning Rate\n",
        "\n",
        "The learning rate is a tuning parameter that determines the step size at each iteration of gradient descent. It determines the speed at which we move down the slope.\n",
        "\n",
        "The step size plays an important part in ensuring a balance between optimization time and accuracy. The step size is measured by a parameter alpha (α). A small α means a small step size, and a large α means a large step size. If the step sizes are too large, we could miss the minimum point completely. This can yield inaccurate results. If the step size is too small, the optimization process could take too much time. This will lead to a waste of computational power.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/learning_rate.png\" width = \"600\" >\n",
        "\n",
        "The step size is evaluated and updated according to the behavior of the cost function. The higher the gradient of the cost function, the steeper the slope and the faster a model can learn (high learning rate). A high learning rate results in a higher step value, and a lower learning rate results in a lower step value. If the gradient of the cost function is zero, the model stops learning."
      ],
      "metadata": {
        "id": "uiPFKxmYFS9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descending the Cost Function\n",
        "\n",
        "Navigating the cost function consists of adjusting the weights. The weights are adjusted using the following formula:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/update.png\" width = \"250\" >\n",
        "\n",
        "This is the formula for gradient descent. As we can see, to obtain the new weight, we use the gradient, the learning rate, and an initial weight.\n",
        "\n",
        "Adjusting the weights consists of multiple iterations. We take a new step down for each iteration and calculate a new weight. Using the initial weight and the gradient and learning rate, we can determine the subsequent weights.\n",
        "\n",
        "Let’s consider a graphical example of this:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/gradient_descent.png\" width = \"600\" >\n",
        "\n",
        "From the graph of the cost function, we can see that:\n",
        "\n",
        "1. To start descending the cost function, we first initialize a random weight.\n",
        "\n",
        "2. Then, we take a step down and obtain a new weight using the gradient and learning rate. With the gradient, we can know which direction to navigate.\n",
        "\n",
        "3. We can know the step size for navigating the cost function using the learning rate.\n",
        "\n",
        "4. We are then able to obtain a new weight using the gradient descent formula.\n",
        "\n",
        "5. We repeat this process until we reach the minimum point of the cost function.\n",
        "\n",
        "6. Once we’ve reached the minimum point, we find the weights that correspond to the minimum of the cost function.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lM8A3EdhF0qS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summarizing Gradient Descent\n",
        "\n",
        "Gradient descent is an optimization algorithm used to find the weights corresponding to the cost function. It needs to descend the cost function until its minimum point to find these weights. It needs the gradient and the learning rate to descend the cost function. The gradient helps find the direction for reaching the minimum point of the cost function. The learning rate helps determine the speed at which to reach the minimum point. Upon reaching the minimum point, gradient descent finds weights corresponding to the minimum point.\n",
        "\n",
        "### Summarizing Backpropagation\n",
        "\n",
        "Backpropagation is the algorithm of calculating the gradients of the cost function with respect to the weights. Backpropagation is used to improve the output of neural networks. It does this by propagating the error in a backward direction and calculating the gradient of the cost function for each weight. These gradients are used in the process of gradient descent.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/difference.png\" width = \"600\" >\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "To put it plainly, gradient descent is the process of using gradients to find the minimum value of the cost function, while backpropagation is calculating those gradients by moving in a backward direction in the neural network. Judging from this, it would be safe to say that gradient descent relies on backpropagation.\n",
        "\n",
        "It would also be plausible to say that the neural network is trained using gradient descent and that backpropagation is only used to assist in the process of calculating the gradients.\n",
        "\n",
        "Although gradient descent is often paired with backpropagation to reduce the error in neural networks, they each perform different functions.\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "- Gradient descent relies on backpropagation. Gradient descent uses gradients to help it find the minimum value of the cost function.\n",
        "\n",
        "- Backpropagation calculates these gradients using the chain rule.\n",
        "Gradient descent is used to find a weight combination that minimizes the cost function.  Backpropagation propagates the error backward and calculates the gradient for each error.\n",
        "\n",
        "- Gradient descent requires the learning rate and the gradient. The gradient helps find the direction to the minimum point of the cost function. The learning rate helps find the speed at which to navigate the cost function.\n",
        "\n",
        "- Together, backpropagation and gradient descent improve the prediction accuracy of neural networks. Backpropagation propagates the error backward and calculates the gradient for each weight. This gradient is used in the process of gradient descent. Gradient descent involves adjusting the weights of the neural network. Adjusting the weights helps minimize the output error of the neural network.\n"
      ],
      "metadata": {
        "id": "7qLTMoNOHUN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## About backward propagation\n",
        "\n",
        "In the first iteration, the predicted values are far from the ground truth values and the distance score will be high. This is because we initially assigned arbitrary values to the network’s parameters (weights and biases). Those values are not optimal values. So, we need to update the values of these parameters in order to minimize the loss function. The process of updating network parameters is called parameter learning or optimization which is done using an optimization algorithm (optimizer) that implements backpropagation.\n",
        "\n",
        "The objective of the optimization algorithm is to find the global minima where the loss function has its minimum value. However, it is a real challenge for an optimization algorithm to find the global minimum of a complex loss function by avoiding all the local minima. If the algorithm is stopped at a local minimum, we’ll not get the minimum value for the loss function. Therefore, our model will not perform well.\n",
        "\n",
        "Here is a list of commonly used optimizers in neural network training.\n",
        "\n",
        "- Gradient Descent\n",
        "- Stocasticc Gradeint Descent (SGD)\n",
        "- Adam\n",
        "- Adagrad\n",
        "- Adadelta\n",
        "- Adamax\n",
        "- Nadam\n",
        "- Ftrl\n",
        "- Root Mean Squared Propagation (RMSProp)\n",
        "\n",
        "In the backward propagation, the partial derivatives (gradients) of the loss function with respect to the model parameters in each layer are calculated. This is done by applying the chain rule of calculus.\n",
        "\n",
        "The derivative of the loss function is its slope which provides us with the direction that we should need to consider for updating (changing) the values of the model parameters.\n",
        "\n",
        "The neural network libraries in Keras provide automatic differentiation. This means, after you define the neural network architecture, the libraries automatically calculate all of the derivates needed for backpropagation.\n",
        "In the backward propagation, calculations are made from the output layer to the input layer (right to left) through the network."
      ],
      "metadata": {
        "id": "1V6dPAxwJU4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The batch size and epochs\n",
        "\n",
        "We do not usually use all training samples (instances/rows) in one iteration during the neural network training. Instead, we specify the batch size which determines the number of training samples to be propagated (forward and backward) during training.\n",
        "\n",
        "An epoch is an iteration over the entire training dataset.\n",
        "For example, let’s say we have a dataset of 1000 training samples and we choose a batch size of 10 and epochs of 20. In this case, our dataset will be divided into 100 (1000/10) batches each with 10 training samples.\n",
        "\n",
        "According to this setting, the algorithm takes the first 10 training samples from the dataset and trains the model. Next, it takes the second 10 training samples and trains the model and so on. Since there is a total of 100 batches, the model parameters will be updated 100 times in each epoch of optimization. This means that one epoch involves 100 batches or 100 times parameter updates. Since the number of epochs is 20, the optimizer passes through the entire training dataset 20 times giving a total of 2000 (100x20) iterations!\n"
      ],
      "metadata": {
        "id": "a6jbSuCpJtJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some commonly used non-linear activation functions\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/non_linear_activation_function.webp\" width = \"600\" >\n",
        "\n",
        "[Source: Introduction To Artificial Intelligence-Part 1](https://dilanbakr.medium.com/introduction-to-artificial-intelligence-part-1-db89f5e81a22)\n"
      ],
      "metadata": {
        "id": "AsGNTSUDy5u5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Choose the Right Activation Function for Neural Networks\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MaralAminpour/ML-BME-Course-UofA-Fall-2023/main/Week-8-Neural-Networks/imgs/activation_functions.webp\" width = \"600\" >\n",
        "\n",
        "\n",
        "[Source](https://towardsdatascience.com/how-to-choose-the-right-activation-function-for-neural-networks-3941ff0e6f9c)"
      ],
      "metadata": {
        "id": "OsSAhM3i0ul-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biological Neural Networks (BNNs) and Artificial Neural Networks (ANNs) have distinct parts that correspond to each other, underpinning their conceptual similarities:\n",
        "\n",
        "**Parts of Biological Neural Networks:**\n",
        "\n",
        "- **Neurons**: The fundamental cells that process and transmit information through electrical and chemical signals.\n",
        "- **Dendrites**: Receive signals from other neurons.\n",
        "- **Soma (Cell Body)**: Integrates incoming signals to determine if the neuron will activate.\n",
        "- **Axon**: Transmits the electrical signal to other neurons.\n",
        "- **Synapses**: Junctions where neurons communicate, using neurotransmitters to send signals.\n",
        "- **Myelin Sheath**: Insulation around some axons that speeds up signal transmission.\n",
        "- **Neurotransmitters**: Chemicals that transmit signals across synapses.\n",
        "\n",
        "**Parts of Artificial Neural Networks:**\n",
        "\n",
        "- **Artificial Neurons (Nodes)**: Basic processing units that simulate biological neurons.\n",
        "- **Inputs**: Analogous to dendrites, they receive data to be processed.\n",
        "- **Weights**: Equivalent to the strength of synaptic connections, determining the influence of inputs.\n",
        "- **Activation Function**: Serves a similar purpose as the soma, deciding the level of output signal based on input strength.\n",
        "- **Outputs**: Correspond to the axon, transmitting the signal to the next layer or as a final output.\n",
        "- **Layers**: Structured groupings of nodes; including input, hidden, and output layers.\n",
        "- **Learning Algorithm (e.g., Backpropagation)**: Method for adjusting weights in the network, similar to how experiences rewire synaptic connections.\n",
        "\n",
        "**Similarities:**\n",
        "\n",
        "- **Signal Processing**: Both BNNs and ANNs process information through a network of interconnected units (neurons/nodes).\n",
        "- **Adaptation**: Neurons in BNNs adapt through changes in synaptic strength, while ANNs adapt through changes in weights.\n",
        "- **Integration and Activation**: Neurons integrate signals and fire based on a threshold; similarly, nodes calculate weighted sums and apply an activation function.\n",
        "- **Transmission**: Just as axons transmit signals to other neurons, ANNs transmit processed data from one node to the next.\n",
        "- **Learning**: Both networks learn from repeated exposure to stimuli (data), although the mechanisms differ (biological processes vs. computational algorithms).\n",
        "\n",
        "The conceptual similarity is rooted in the inspiration ANNs take from BNNs, using an abstracted and simplified model to replicate the complex patterns of data processing and learning observed in biological systems."
      ],
      "metadata": {
        "id": "Iqgleg_I_4iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.itechcreations.in/artificial-intelligence/artificial-neural-network-for-dummies-an-introduction/\n",
        "\n",
        "https://www.upgrad.com/blog/neural-networks-for-dummies-a-comprehensive-guide/\n",
        "\n",
        "https://ai.plainenglish.io/neural-networks-for-dummies-841a404be413\n",
        "\n",
        "https://talendor.io/neural-networks-for-dummies\n",
        "\n",
        "https://www.freecodecamp.org/news/neural-networks-for-dummies-a-quick-intro-to-this-fascinating-field-795b1705104a/\n",
        "\n",
        "https://vidyaesampally1998.medium.com/artificial-neural-network-v-s-biological-neural-network-a0862d12e9a8\n",
        "\n",
        "https://cs231n.github.io/neural-networks-1/\n",
        "\n",
        "https://dilanbakr.medium.com/introduction-to-artificial-intelligence-part-1-db89f5e81a22\n",
        "\n",
        "\n",
        "https://www.geeksforgeeks.org/artificial-neural-networks-and-its-applications/\n",
        "\n",
        "https://www.mdpi.com/2076-3425/12/7/863\n",
        "\n",
        "https://www.xenonstack.com/blog/artificial-neural-network-applications\n",
        "\n"
      ],
      "metadata": {
        "id": "TYGg2j2G9SB8"
      }
    }
  ]
}